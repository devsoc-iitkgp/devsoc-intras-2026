# MetaKGP Wiki Scraper & Vector Database

A Python project that scrapes the MetaKGP wiki, processes article content, and builds a searchable vector database using Google's Generative AI embeddings and FAISS.

---

## Team Name: [Insert Team Name]

### ğŸ‘¥ Team Members
- Member 1: Abhinav Bhardwaj- [abhinav2428]
- Member 2: Anshika - [Ancoderk]
- Member 3: Varad - [varad-oss]


## ğŸ¤– Technical Implementation

### 1. Data Pipeline (Scraping)

**Tools Used:**
- Beautiful Soup 4 - HTML parsing and content extraction
- Requests - HTTP client for API calls
- PyWikiBot - Wiki API interaction

**Strategy:** 
The scraper follows a three-stage pipeline:
1. **URL Discovery** - Fetch all article URLs from the MetaKGP API (main.py)
2. **Content Extraction** - Download and process article content with HTML cleaning (fetch_content.py)
3. **Vectorization** - Create embeddings and build FAISS index using Google's API (ingest_modal.py)

The scraper handles:
- HTML content cleaning and text extraction
- UTF-8 encoding issues gracefully
- Rate limiting (0.1s delay per request)
- Network timeouts with retry logic
- Batch processing with configurable sizes (default: 100 pages per batch)

**Indexing:** FAISS vector database powered by Google's Generative AI embeddings (`text-embedding-004`)

### 2. Graph of Thoughts (GoT)

**Reasoning Model:**
- Nodes represent individual MetaKGP wiki articles/pages
- Edges represent internal wiki links connecting related pages
- Each node stores: article URL, title, cleaned content, and embedding vector

**Graph Logic:**
Knowledge graph connects different MetaKGP pages by:
- Extracting outgoing wiki links from article content
- Creating edges between "Society" pages, "Student" pages, "Academic" pages, etc.
- Enabling semantic traversal: e.g., a "Society" page links to associated "Student" members
- NetworkX generates graph structure in GML format for visualization and analysis
- Allows multi-hop reasoning across related knowledge domains

### 3. Mixture of Experts (MoE)

**Expert 1 (Source Matcher):**
- Verifies retrieved text exists in the scraped MetaKGP data
- Cross-references embeddings with original content
- Returns exact source URL and article title

**Expert 2 (Hallucination Hunter):**
- Detects fabricated or inconsistent information
- Validates semantic coherence with source content
- Flags low-confidence matches below similarity threshold

**Expert 3 (Logic Expert):**
- Ensures logical consistency across linked pages
- Verifies citations and references between articles
- Maintains factual integrity through graph traversal

---

## ğŸ“Š Setup Instructions

### Prerequisites
- Python 3.8+
- pip (Python package manager)
- Google Generative AI API key (free from [Google AI Studio](https://aistudio.google.com/app/apikey))
- Modal account (for cloud ingestion - optional)
- Internet connection

---

## ğŸ“Š Setup Instructions

### Prerequisites
- Python 3.8+
- pip (Python package manager)
- Google Generative AI API key (free from [Google AI Studio](https://aistudio.google.com/app/apikey))
- Modal account (for cloud ingestion - optional)
- Internet connection

### Environment Variables

Create a `.env` file in the project root (do not share actual keys):

```
GOOGLE_API_KEY=your_google_generative_ai_key_here
MODAL_TOKEN_PATH=/path/to/modal/token  # Optional, for cloud deployment
```

**Required Environment Keys:**
- `GOOGLE_API_KEY` - Google Generative AI API key for embedding generation

### How to Run

#### 1. Installation & Setup

```bash
# Clone the repository
git clone <repository-url>
cd Team_3

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Run Scraper (Fetch & Index)

```bash
# Step 1: Fetch all wiki article URLs
python main.py

# Step 2: Download and process article content
python fetch_content.py

# Step 3: Create vector database and knowledge graph (Cloud)
# Update GOOGLE_API_KEY in ingest_modal.py first
python ingest_modal.py
```

#### 3. Run Bot/Chat Interface

```bash
# Start the Streamlit chat interface
streamlit run app.py

# Or run the basic bot
python bot.py
```

#### Quick Start
```bash
# Run all steps in sequence
python run.py
```

---

## ğŸ“¸ Screenshots

[Image of Graph Visualization]

[Image of Chat Interface]
![alt text](<Screenshot 2026-01-17 160652.png>)
---

## Requirements

## Project Structure

```
Team_3/
â”œâ”€â”€ main.py                      # Fetch all wiki article URLs
â”œâ”€â”€ fetch_content.py             # Download and process article content
â”œâ”€â”€ ingest_modal.py              # Cloud ingestion with Google embeddings
â”œâ”€â”€ app.py                       # Streamlit chat interface
â”œâ”€â”€ bot.py                       # Bot implementation
â”œâ”€â”€ run.py                       # Quick start script
â”œâ”€â”€ families/
â”‚   â””â”€â”€ metakgp_family.py        # PyWikiBot family configuration
â”œâ”€â”€ metakgp_data/                # Generated batch JSON files
â”œâ”€â”€ faiss_index/                 # Generated FAISS vector index
â”œâ”€â”€ static/                      # Frontend assets
â”‚   â”œâ”€â”€ index.html               # Chat UI
â”‚   â”œâ”€â”€ script.js                # Frontend logic
â”‚   â””â”€â”€ styles.css               # Styling
â”œâ”€â”€ all_article_urls.txt         # Generated URL list
â”œâ”€â”€ metakgp_graph.gml            # Generated knowledge graph
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ ARCHITECTURE/
â”‚   â””â”€â”€ ARCHITECTURE.md          # Detailed technical documentation
â”œâ”€â”€ FRONT_END/
â”‚   â””â”€â”€ README.md                # Frontend documentation
â””â”€â”€ README.md                    # This file
```

## Key Features

- âœ… Automated wiki scraping via MetaKGP API
- âœ… HTML content cleaning and text extraction
- âœ… Batch processing with configurable sizes
- âœ… Knowledge graph generation using NetworkX
- âœ… Cloud-based embedding generation with Modal
- âœ… FAISS vector database for semantic search
- âœ… Graceful error handling and progress logging
- âœ… Mixture of Experts architecture for fact verification
- âœ… Web-based chat interface (Streamlit)

## Dependencies

Core Dependencies:
- `requests` - HTTP client for API calls
- `beautifulsoup4` - HTML parsing and content extraction
- `langchain` - LLM framework
- `langchain-google-genai` - Google embeddings integration
- `langchain-text-splitters` - Text chunking
- `faiss-cpu` - Vector similarity search
- `networkx` - Graph data structure
- `pywikibot` - Wiki API interaction

Optional (for cloud deployment):
- `modal` - Cloud compute platform
- `streamlit` - Web interface framework

Install all dependencies:
```bash
pip install -r requirements.txt
```

## Troubleshooting

| Issue | Solution |
|-------|----------|
| `all_article_urls.txt not found` | Run `python main.py` first to generate the URL list |
| `API Error: Page not found` | Some wiki pages may be deleted or redirected. Check at `https://wiki.metakgp.org/wiki/PageName` |
| `FAISS import error` | Reinstall: `pip install --force-reinstall faiss-cpu` |
| `Google API key error` | Verify API key is correct and has Generative AI access enabled |
| `Modal authentication failed` | Run `modal token new` to set up Modal credentials |

## Performance Considerations

1. **Batch Size**: Adjust `BATCH_SIZE` in `fetch_content.py`:
   - Smaller batches (10-50) for slow connections
   - Larger batches (200-500) for high-speed connections

2. **Rate Limiting**: Built-in 0.1s delay between requests to be respectful to the wiki server

3. **Cloud Ingestion**: Modal handles parallel processing for faster embedding generation

## Security Notes

âš ï¸ **Important:** Never commit sensitive credentials to the repository:
- Use `.env` files for local configuration (add to `.gitignore`)
- Store API keys securely
- Use environment variables in production
- Rotate keys regularly if exposed

## License

Distributed under the MIT License. See LICENSE.txt for more information.

## Contact & Support

For issues, questions, or suggestions, please open an issue on the GitHub repository.

---

**Note:** This project is designed for the MetaKGP wiki. Adaptation to other wikis may require configuration changes.

**Last Updated:** January 2026
